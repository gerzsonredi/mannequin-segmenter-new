{
  "timestamp": "2025-07-26T15:40:44.636018",
  "test_results": {
    "config": {
      "batch_size": 10,
      "concurrent_batches": 3,
      "total_images": 50,
      "image_set": "small",
      "upload_s3": false,
      "use_optimized_endpoint": true
    },
    "summary": {
      "total_duration": 35.87649416923523,
      "successful_batches": 0,
      "failed_batches": 1,
      "total_successful_images": 0,
      "total_failed_images": 0,
      "overall_throughput": 0.0,
      "avg_batch_throughput": 0
    },
    "batch_stats": {
      "avg_duration": 0,
      "median_duration": 0,
      "min_duration": 0,
      "max_duration": 0
    },
    "batches": [
      {
        "status": "error",
        "duration": 35.679208755493164,
        "http_status": 500,
        "error": "{\"error\":\"Optimized batch processing failed: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 22.17 GiB of which 2.18 GiB is free. Process 956 has 19.98 GiB memory in use. 19.95 GiB allowed; Of the allocated memory 18.65 GiB is allocated by PyTorch, with 236.00 MiB allocated in private pools (e.g., CUDA Graphs), and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\"}\n"
      }
    ],
    "monitoring": [
      {
        "timestamp": 1753537208.892482,
        "datetime": "2025-07-26T15:40:08.892482",
        "active_requests": 1,
        "available_models": 21,
        "gpu_memory": {
          "allocated_gb": 18.33533239364624,
          "max_allocated_gb": 18.70060157775879,
          "reserved_gb": 19.90234375
        },
        "initialized": true,
        "max_active_requests": 3,
        "pool_size": 22,
        "total_requests": 3
      },
      {
        "timestamp": 1753537213.988374,
        "datetime": "2025-07-26T15:40:13.988374",
        "active_requests": 1,
        "available_models": 21,
        "gpu_memory": {
          "allocated_gb": 18.33533239364624,
          "max_allocated_gb": 18.70060157775879,
          "reserved_gb": 19.90234375
        },
        "initialized": true,
        "max_active_requests": 3,
        "pool_size": 22,
        "total_requests": 3
      },
      {
        "timestamp": 1753537219.108247,
        "datetime": "2025-07-26T15:40:19.108247",
        "active_requests": 1,
        "available_models": 21,
        "gpu_memory": {
          "allocated_gb": 18.33533239364624,
          "max_allocated_gb": 18.70060157775879,
          "reserved_gb": 19.90234375
        },
        "initialized": true,
        "max_active_requests": 3,
        "pool_size": 22,
        "total_requests": 3
      },
      {
        "timestamp": 1753537224.232251,
        "datetime": "2025-07-26T15:40:24.232251",
        "active_requests": 1,
        "available_models": 21,
        "gpu_memory": {
          "allocated_gb": 18.33533239364624,
          "max_allocated_gb": 18.70060157775879,
          "reserved_gb": 19.90234375
        },
        "initialized": true,
        "max_active_requests": 3,
        "pool_size": 22,
        "total_requests": 3
      },
      {
        "timestamp": 1753537229.373856,
        "datetime": "2025-07-26T15:40:29.373856",
        "active_requests": 1,
        "available_models": 21,
        "gpu_memory": {
          "allocated_gb": 18.33533239364624,
          "max_allocated_gb": 18.70060157775879,
          "reserved_gb": 19.90234375
        },
        "initialized": true,
        "max_active_requests": 3,
        "pool_size": 22,
        "total_requests": 3
      },
      {
        "timestamp": 1753537234.448597,
        "datetime": "2025-07-26T15:40:34.448597",
        "active_requests": 1,
        "available_models": 21,
        "gpu_memory": {
          "allocated_gb": 18.382930278778076,
          "max_allocated_gb": 19.029293060302734,
          "reserved_gb": 19.49609375
        },
        "initialized": true,
        "max_active_requests": 1,
        "pool_size": 22,
        "total_requests": 1
      },
      {
        "timestamp": 1753537239.521156,
        "datetime": "2025-07-26T15:40:39.521156",
        "active_requests": 1,
        "available_models": 21,
        "gpu_memory": {
          "allocated_gb": 18.382930278778076,
          "max_allocated_gb": 19.029293060302734,
          "reserved_gb": 19.49609375
        },
        "initialized": true,
        "max_active_requests": 1,
        "pool_size": 22,
        "total_requests": 1
      }
    ],
    "final_pool_stats": {
      "pool_statistics": {
        "active_requests": 1,
        "available_models": 21,
        "gpu_memory": {
          "allocated_gb": 18.33533239364624,
          "max_allocated_gb": 18.70060157775879,
          "reserved_gb": 19.90234375
        },
        "initialized": true,
        "max_active_requests": 3,
        "pool_size": 22,
        "total_requests": 3
      },
      "timestamp": "2025-07-26T13:40:44.644199"
    }
  }
}